{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need headers to disguise our bot as a browser\n",
    "\n",
    "headers = {\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.131 Safari/537.36\",\n",
    "    \"Accept-Encoding\": \"gzip,deflate,sdch\",\n",
    "    \"Accept-Language\": \"zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4,zh-TW;q=0.2\",\n",
    "}\n",
    "\n",
    "import requests\n",
    "from scrapy.http import TextResponse\n",
    "\n",
    "r = requests.get('https://www.jstor.org/journal/amereconrevi', \n",
    "                 headers = headers)\n",
    "\n",
    "response = TextResponse(r.url, body = r.text, encoding = 'utf-8')\n",
    "\n",
    "# there is a response we need to handle\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Define here the models for your scraped items\n",
    "#\n",
    "# See documentation in:\n",
    "# http://doc.scrapy.org/en/latest/topics/items.html\n",
    "\n",
    "from scrapy import Item, Field\n",
    "\n",
    "\n",
    "class DocumentItem(Item):\n",
    "    # define the fields for your item here like:\n",
    "    # name = scrapy.Field()\n",
    "    abstract = Field()\n",
    "\n",
    "    publication_date = Field()\n",
    "    submission_date = Field()\n",
    "    online_date = Field()\n",
    "    revision_date = Field()\n",
    "    accepted_date = Field()\n",
    "\n",
    "    title = Field()\n",
    "    coverpage_url = Field()\n",
    "    fpage = Field()\n",
    "    lpage = Field()\n",
    "    pages = Field()\n",
    "    submission_path = Field()\n",
    "\n",
    "    publication_title = Field()\n",
    "\n",
    "\n",
    "class KeywordItem(Item):\n",
    "    keyword = Field()\n",
    "\n",
    "    title = Field()\n",
    "\n",
    "\n",
    "class SourceItem(Item):\n",
    "    publication_title = Field()\n",
    "    chief_editor = Field()\n",
    "    issn = Field()\n",
    "    description = Field()\n",
    "    home_url = Field()\n",
    "    coverimage = Field()\n",
    "\n",
    "    title = Field()\n",
    "\n",
    "class AuthorItem(Item):\n",
    "    institution = Field()\n",
    "    email = Field()\n",
    "    avatar = Field()\n",
    "    vitae = Field()\n",
    "    fname = Field()\n",
    "    lname = Field()\n",
    "    address = Field()\n",
    "\n",
    "    title = Field()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Structure\n",
    "\n",
    "`UPDATE: 2017.6.25 00:39`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.xpath('.//dl[@class=\"accordion\"]/@data-decade').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://www.jstor.org/journal/acadmanaj?decade=1990'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.jstor.org/journal/amereconrevi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ base_url + '?decade=' + i for i in response.xpath('.//dl[@class=\"accordion\"]/@data-decade').extract()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://www.jstor.org/stable/i302974'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jstor_url = 'https://www.jstor.org'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[jstor_url + i for i in response.xpath('.//li[@data-doi]/a/@href').extract()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.jstor.org/stable/10.2307/i29780254', \n",
    "                 headers = headers)\n",
    "\n",
    "response = TextResponse(r.url, body = r.text, encoding = 'utf-8')\n",
    "\n",
    "# there is a response we need to handle\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[jstor_url + i for i in response.xpath('.//div[@class=\"media-body media-object-section main-section\"]/a/@href').extract()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.jstor.org/stable/10.1086/666616', \n",
    "                 headers = headers)\n",
    "\n",
    "response = TextResponse(r.url, body = r.text, encoding = 'utf-8')\n",
    "# there is a response we need to handle\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = dict(\n",
    "    title = './/h1[@class=\"title\"]/text()',\n",
    "    # submission_path, publication_date, page\n",
    "    meta = './/*[@class=\"src mbl\"]/text()',\n",
    "    abstract = './/*[@class=\"abstract1\"]/text()'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.xpath(document['abstract']).extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.xpath(document['title']).extract()[0].replace('\\n', '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = response.xpath(document['meta']).extract()[0].replace('\\n', '').strip()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "meta = re.split('[()]', response.xpath(document['meta']).extract()[0].replace('\\n', '').strip())\n",
    "pages = [ int(i) for i in meta[-1].split('pp.')[-1].split('-')]\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "from scrapy.loader import ItemLoader\n",
    "from scrapy.loader.processors import Join, TakeFirst\n",
    "import re\n",
    "\n",
    "def load_document(response, document):\n",
    "    l = ItemLoader(item = DocumentItem(), response = response)\n",
    "    l.default_output_processor = TakeFirst()\n",
    "    \n",
    "    l.add_value('coverpage_url', response.url)\n",
    "    l.add_xpath('abstract', document['abstract'])\n",
    "    l.add_value('title', response.xpath(document['title']).extract()[0].replace('\\n', '').strip())\n",
    "    meta = re.split('[()]', response.xpath(document['meta']).extract()[0].replace('\\n', '').strip())\n",
    "    try:\n",
    "        l.add_value('submission_path', meta[0])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        l.add_value('publication_date', parse(meta[1]))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # handle pages\n",
    "    try:\n",
    "        pages = [ int(i) for i in meta[-1].split('pp.')[-1].split('-')]\n",
    "        fp = pages[0]\n",
    "        lp = pages[-1]\n",
    "        l.add_value('fpage', fp)\n",
    "        l.add_value('lpage', lp)\n",
    "        l.add_value('pages', lp-fp+1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # mark it down, with source's publication_title\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = load_document(response, document)\n",
    "l.load_item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = './/*[@class=\"topics mtl\"]/a/text()'\n",
    "\n",
    "response.xpath(keyword).extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  4.Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author = dict(names = './/*[@class=\"contrib\"]/text()')\n",
    "\n",
    "string = response.xpath(author['names']).extract()[0].replace('\\n', '').strip()\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "names = [str.strip(i) for i in string.replace(' and ', ', ').split(',')]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = names[0].split()\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_author(response, author):\n",
    "    string = response.xpath(author['names']).extract()[0].replace('\\n', '').strip()\n",
    "    names = [str.strip(i) for i in string.replace(' and ', ', ').split(',')]\n",
    "    for name in names:\n",
    "        l = ItemLoader(item = AuthorItem(), response = response)\n",
    "        l.default_output_processor = TakeFirst()\n",
    "        # author's first name and last name\n",
    "        flname = name.split()\n",
    "        fn = flname[0]\n",
    "        ln = flname[-1]\n",
    "        l.add_value('fname', fn)\n",
    "        l.add_value('lname', ln)\n",
    "        yield l\n",
    "\n",
    "for i in list(load_author(response, author)):\n",
    "    print(i.load_item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Source\n",
    "\n",
    "`UPDATED: 2017.6.23 17:16`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.jstor.org/journal/jconsrese', \n",
    "                 headers = headers)\n",
    "\n",
    "response = TextResponse(r.url, body = r.text, encoding = 'utf-8')\n",
    "# there is a response we need to handle\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.xpath('.//*[@class=\"journal_info_button\"]/a/@href').extract()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jstor_url = 'https://www.jstor.org'\n",
    "jstor_url + response.xpath('.//*[@class=\"journal_info_button\"]/a/@href').extract()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.jstor.org/journal/acadmanaj?item_view=journal_info', \n",
    "                 headers = headers)\n",
    "\n",
    "response = TextResponse(r.url, body = r.text, encoding = 'utf-8')\n",
    "# there is a response we need to handle\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = dict(\n",
    "    issn = '//div[@class=\"issn mtm\"]/text()',\n",
    "    publication_title = './/div[@class=\"journal lookslikeh2 drop-content-title\"]/text()',\n",
    "    description = './/div[@class=\"journal_description mtm\"]',\n",
    "    subjects = './/div[@class=\"subjects mtm\"]',\n",
    "    collections = './/div[@class=\"collections mtm\"]',\n",
    "    coverimage = './/img[@class=\"cover\"]/@src'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_descrip(key, response, source):\n",
    "    ''' Inner Function '''  \n",
    "    try:\n",
    "        a =response.xpath(source[key])[0].extract()\n",
    "        b = cleanhtml(a).replace('  ','').replace(\"&amp\", '') \n",
    "    except:\n",
    "        b  = ''\n",
    "    value = b.replace('\\n','')\n",
    "    return value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_descrip('description', response, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \" \".join([ _get_descrip(j, response, source) for j in ['description', 'subjects', 'collections']])\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.xpath(source['issn']).extract()[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.loader.processors import Join, TakeFirst\n",
    "from scrapy.loader import ItemLoader\n",
    "\n",
    "def _get_descrip(key, response, source):\n",
    "    ''' Inner Function '''  \n",
    "    try:\n",
    "        a =response.xpath(source[key])[0].extract()\n",
    "        b = cleanhtml(a).replace('  ','').replace(\"&amp\", '') \n",
    "    except:\n",
    "        b  = ''\n",
    "    value = b.replace('\\n','')\n",
    "    return value\n",
    "\n",
    "def load_source(response, source):\n",
    "    l = ItemLoader(item = SourceItem(), response = response)\n",
    "    l.default_output_processor = TakeFirst()\n",
    "    l.add_xpath(\"issn\", source['issn'])\n",
    "    l.add_xpath('publication_title', source['publication_title'])\n",
    "    description = \" \".join([ _get_descrip(j, response, source) for j in ['description', 'subjects', 'collections']])\n",
    "    l.add_value('description', description)\n",
    "    l.add_value('home_url', response.url)\n",
    "    # l.add_xpath('coverimage', response.meta.get('coverimage'))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = load_source(response, source)\n",
    "l.load_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'efasdfsdfadsfas'\n",
    "s[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
