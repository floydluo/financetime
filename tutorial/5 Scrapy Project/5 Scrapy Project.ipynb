{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn About Scrapy Project Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Start a Project\n",
    "\n",
    "In the former tutorials, we have explored scrapy's powerful objects and methods. \n",
    "\n",
    "From now on, we will explore scrapy project structure in order run it in the terminal and yield the items we want to get from the websits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Open your terminal and enter the following commands to start a scrapy project**\n",
    "\n",
    "---\n",
    "\n",
    "```bash\n",
    "$ scrapy startproject firstpro\n",
    "\n",
    "$ cd firstpro\n",
    "\n",
    "$ tree\n",
    "\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](startfintime50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files inside the Projects\n",
    "\n",
    "There are many files already generated in this project package.\n",
    "\n",
    "Then I will give a brief introduction to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1  `scrapy.cfg`\n",
    "\n",
    "**Configuration file**\n",
    "\n",
    "Some configurations for your projects.\n",
    "\n",
    "You do not even bother to study or write this file.\n",
    "\n",
    "As this file is generated by `scrapy` already.\n",
    "    \n",
    "    \n",
    "**File contents**:\n",
    "\n",
    "---\n",
    "\n",
    "```cfg\n",
    "# Automatically created by: scrapy startproject\n",
    "#\n",
    "# For more information about the [deploy] section see:\n",
    "# https://scrapyd.readthedocs.org/en/latest/deploy.html\n",
    "\n",
    "[settings]\n",
    "default = fintime50.settings\n",
    "\n",
    "[deploy]\n",
    "#url = http://localhost:6800/\n",
    "project = fintime50\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**When you turn to `fintime50` folder**\n",
    "\n",
    "You will find there are four python files:\n",
    "\n",
    "`__init__.py`\n",
    "\n",
    "`settings.py`\n",
    "\n",
    "`items.py`\n",
    "\n",
    "`pipelines.py`\n",
    "\n",
    "and a folder named `spiders`.\n",
    "\n",
    "---\n",
    "\n",
    "### 0 `__init__.py`\n",
    "\n",
    "This python file contains nothing.\n",
    "\n",
    "It is here for the concern to unitify the whole project.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 `settings.py`\n",
    "\n",
    "\n",
    "This settings.py contains settings which control the behaviors of the spiders inside this project.\n",
    "\n",
    "Open this file and you will find there are many lines of sentences, \n",
    "\n",
    "and most of them are commented away by `#`.\n",
    "\n",
    "So, the acutal valid codes are:\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "\n",
    "BOT_NAME = 'fintime50'\n",
    "\n",
    "SPIDER_MODULES = ['fintime50.spiders']\n",
    "NEWSPIDER_MODULE = 'fintime50.spiders'\n",
    "\n",
    "\n",
    "ROBOTSTXT_OBEY = True\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Here are some items you need to modified, therefore, your spider can run well.\n",
    "\n",
    "\n",
    "Which includes:\n",
    "\n",
    "`ROBOTSTXT_OBEY`: turn it to `False`, it is just fine!\n",
    "\n",
    "`DEFAULT_REQUEST_HEADERS`: give spiders strong headers to hide.\n",
    "\n",
    "`ITEM_PIPELINES`: the pipelines will convey it yield items to the destination. More information when talking about `pipelines.py`.\n",
    "\n",
    "\n",
    "\n",
    "So the modified `settings.py` is:\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "BOT_NAME = 'fintime50'\n",
    "\n",
    "SPIDER_MODULES = ['fintime50.spiders']\n",
    "NEWSPIDER_MODULE = 'fintime50.spiders'\n",
    "\n",
    "ROBOTSTXT_OBEY = False\n",
    "\n",
    "DEFAULT_REQUEST_HEADERS = {\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.131 Safari/537.36\",\n",
    "    \"Accept-Encoding\": \"gzip,deflate,sdch\",\n",
    "    \"Accept-Language\": \"zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4,zh-TW;q=0.2\",\n",
    "}\n",
    "\n",
    "ITEM_PIPELINES = {\n",
    "   'fintime50.pipelines.Fintime50Pipeline': 300,\n",
    "}\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 `items.py`\n",
    "\n",
    "When you open `items.py` file, you will find:\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "```python\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class Fintime50Item(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    # name = scrapy.Field()\n",
    "    pass\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Essentially, there are nothing here.\n",
    "\n",
    "\n",
    "This file contains the `item` you defined which is used to contain the items you scrape from the Internet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, in the fourth tutorial `ItemLoader`, `Item` have been introduced.\n",
    "\n",
    "Such as this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scrapy import Item, Field\n",
    "class SourceItem(Item):\n",
    "    publication_title = Field()\n",
    "    chief_editor = Field()\n",
    "    issn = Field()\n",
    "    description = Field()\n",
    "    home_url = Field()\n",
    "    coverimage = Field()\n",
    "    title = Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intialization\n",
    "item = SourceItem()\n",
    "isinstance(item, SourceItem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coverimage': 'imageurl', 'issn': '1234'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it acts in the way of dictionary\n",
    "item['issn'] = '1234'\n",
    "item['coverimage'] = 'imageurl'\n",
    "item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this python file, every item is defined here.\n",
    "\n",
    "For our project, we need `items` to contain `sources`, `authors`, `documents` and `keywords`.\n",
    "\n",
    "So the file turns out in this way.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "from scrapy import Item, Field\n",
    "\n",
    "\n",
    "class DocumentItem(Item):\n",
    "    # define the fields for your item here like:\n",
    "    # name = scrapy.Field()\n",
    "    abstract = Field()\n",
    "\n",
    "    publication_date = Field()\n",
    "    submission_date = Field()\n",
    "    online_date = Field()\n",
    "    revision_date = Field()\n",
    "    accepted_date = Field()\n",
    "\n",
    "    title = Field()\n",
    "    coverpage_url = Field()\n",
    "    fpage = Field()\n",
    "    lpage = Field()\n",
    "    pages = Field()\n",
    "    submission_path = Field()\n",
    "\n",
    "    publication_title = Field()\n",
    "\n",
    "\n",
    "class KeywordItem(Item):\n",
    "    keyword = Field()\n",
    "\n",
    "    title = Field()\n",
    "\n",
    "\n",
    "class SourceItem(Item):\n",
    "    publication_title = Field()\n",
    "    chief_editor = Field()\n",
    "    issn = Field()\n",
    "    description = Field()\n",
    "    home_url = Field()\n",
    "    coverimage = Field()\n",
    "\n",
    "    title = Field()\n",
    "\n",
    "class AuthorItem(Item):\n",
    "    institution = Field()\n",
    "    email = Field()\n",
    "    avatar = Field()\n",
    "    vitae = Field()\n",
    "    fname = Field()\n",
    "    lname = Field()\n",
    "    address = Field()\n",
    "\n",
    "    title = Field()\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some tricks here, such as both AuthorItem, KeywordsItem contain the field `title`.\n",
    "\n",
    "Actually, this is the sign to identify the relationship between authors, keywords and documents.\n",
    "\n",
    "This is used to store the items into Database via pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 `pipelines.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When opening the `pipelines.py`, you will find:\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Define your item pipelines here\n",
    "#\n",
    "# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n",
    "# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html\n",
    "\n",
    "class Fintime50Pipeline(object):\n",
    "    def process_item(self, item, spider):\n",
    "        return item\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "When `items` is scraped, or yielded from spiders, they will be processed by `Pipeline.process_item` method.\n",
    "\n",
    "Then, they will appear in the terminal.\n",
    "\n",
    "For now, these codes are enough.\n",
    "\n",
    "Actually, writing the items into the database is acheived in the this process.\n",
    "\n",
    "And, definitely, more codes are needed, as well as a database.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
